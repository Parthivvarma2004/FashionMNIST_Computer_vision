{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCUXs7t8rejIZ620VglBGM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parthivvarma2004/FashionMNIST_Computer_vision/blob/main/FashionMNIST_Computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PXfpNdoZRzOI"
      },
      "outputs": [],
      "source": [
        "#Importing dependencies\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading training and testing data\n",
        "train_data = datasets.FashionMNIST(root = 'data', train = True, download = True, transform = ToTensor())\n",
        "test_data = datasets.FashionMNIST(root = 'data', train = False, download = True, transform = ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjrMcuZRSsd9",
        "outputId": "9745ab3e-830d-43d7-bee4-63c05863dc3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 8335691.80it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 139917.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2622806.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 20312584.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if data has been downloaded in the correct way\n",
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhzTUKdXTXt5",
        "outputId": "950a33e7-f772-4bad-9b01-851e56fdf107"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07t7DBIWafpA",
        "outputId": "877d8260-f1ac-4a0f-9c38-b1c312d104cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC3e27Faa-kl",
        "outputId": "c7c169d4-99e2-4497-d7a4-d125d5502da7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "           0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,   1,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
              "          36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,   0,   3],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,\n",
              "         102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,  15],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  69,\n",
              "         207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88, 172,  66],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0, 200,\n",
              "         232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196, 229,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 183,\n",
              "         225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245, 173,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 193,\n",
              "         228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243, 202,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12, 219,\n",
              "         220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244,\n",
              "         222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55, 236,\n",
              "         228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,  92,   0],\n",
              "        [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237, 226,\n",
              "         217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,  77,   0],\n",
              "        [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228, 207,\n",
              "         213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244, 159,   0],\n",
              "        [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217, 226,\n",
              "         200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238, 215,   0],\n",
              "        [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200, 159,\n",
              "         245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232, 246,   0],\n",
              "        [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80,\n",
              "         150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0],\n",
              "        [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
              "          65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,  29],\n",
              "        [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198, 213,\n",
              "         240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221, 230,  67],\n",
              "        [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219, 221,\n",
              "         220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205, 206, 115],\n",
              "        [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211, 210,\n",
              "         200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177, 210,  92],\n",
              "        [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189, 188,\n",
              "         193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216, 170,   0],\n",
              "        [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244, 221,\n",
              "         220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH9U206vbEWo",
        "outputId": "f3cebceb-dd86-47e5-c072-4bb68d3ef9c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display all the different labels/class names\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehgx0Eb9bTnC",
        "outputId": "9e32d131-50b7-4857-c057-fb3a24c5293b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the image for data visualization\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(class_names[label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "s0S87sdObUQC",
        "outputId": "09c45886-c830-4305-8448-3c325ee3d098"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ankle boot')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = False)"
      ],
      "metadata": {
        "id": "fV4kQnbIbUNh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VvSU3_TbULJ",
        "outputId": "eff30234-3a17-4282-f62c-213ce7cd7e79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1875"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7biogznbbT-S",
        "outputId": "a5321fab-aaf8-4b1f-a6e4-3c562340a90f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "313"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we flatten our tensors as linear layers in the nn module work with single vectors\n",
        "#First attempt at building a solution - linear and non linear layers (Relu())\n",
        "from torch import nn\n",
        "class ModelV0(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(nn.Flatten(),\n",
        "                                      nn.Linear(in_features=input_shape, out_features = hidden_units),\n",
        "                                      nn.ReLU(),\n",
        "                                      nn.Linear(in_features = hidden_units, out_features = output_shape),\n",
        "                                      nn.ReLU()\n",
        "                                      )\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "Cqy2T70Uglgv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we define the gpu as device to make the process faster\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yugytv2qSWL5",
        "outputId": "ff64edfa-9675-45da-f664-15ab8abedf4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Flattening the model will cause the vector to be of size 28*28 = 784, so we use input_shape = 784, hidden_units = 10 (arbitrary small number),\n",
        "#and output_units = len(class_names)\n",
        "\n",
        "model_0  = ModelV0(input_shape = 784, hidden_units = 10, output_shape = len(class_names)).to(device)\n"
      ],
      "metadata": {
        "id": "qhkmqtDxR8yp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ul__5MV7mY",
        "outputId": "b5817534-866a-4464-eb3b-85fdd11b6ad7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0185, -0.0329,  0.0232,  ..., -0.0198, -0.0250,  0.0347],\n",
              "        [ 0.0354,  0.0118, -0.0302,  ..., -0.0114,  0.0286,  0.0073],\n",
              "        [-0.0121,  0.0157, -0.0126,  ...,  0.0334,  0.0302, -0.0356],\n",
              "        ...,\n",
              "        [ 0.0092, -0.0231,  0.0224,  ..., -0.0018, -0.0279, -0.0037],\n",
              "        [ 0.0020,  0.0311, -0.0110,  ..., -0.0018, -0.0052, -0.0324],\n",
              "        [ 0.0240,  0.0123, -0.0256,  ...,  0.0178, -0.0014,  0.0302]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_0.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD902q9NWQ5E",
        "outputId": "490e9dc1-b6b1-4cff-8075-be839dfc2096"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "eH5gToh0Wket"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an accuracy function to use later\n",
        "def accuracy_fn(y_true: torch.Tensor, y_pred: torch.Tensor):\n",
        "  matches = torch.eq(y_true, y_pred).sum().item()\n",
        "  return ((matches/len(y_pred))*100)"
      ],
      "metadata": {
        "id": "P-Z3v4XQfD8Q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and testing functions\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataLoader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device:torch.device = device):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  model.to(device)\n",
        "  for batch, (X,y) in  enumerate(dataLoader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    train_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(train_pred,y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true = y, y_pred = train_pred.argmax(dim=1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(dataLoader)\n",
        "  train_acc /= len(dataLoader)\n",
        "  print(f\"Train loss: {train_loss:.5f} , Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "def test_step(dataLoader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, y in dataLoader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            test_pred = model(X)\n",
        "\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "        test_loss /= len(dataLoader)\n",
        "        test_acc /= len(dataLoader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "uphPnZqKdhdb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "train_time_start = timer()\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch: {epoch}\\n\")\n",
        "  train_step(dataLoader = train_dataloader,\n",
        "             model = model_0,\n",
        "             optimizer = optimizer,\n",
        "             loss_fn = loss_function,\n",
        "             accuracy_fn = accuracy_fn)\n",
        "  test_step(dataLoader=test_dataloader,\n",
        "            model=model_0,\n",
        "            loss_fn=loss_function,\n",
        "            accuracy_fn=accuracy_fn\n",
        "            )\n",
        "  train_time_end = timer()\n",
        "  print(f\"It took {train_time_end - train_time_start} seconds to complete the process\\n\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es16RVq-8aBS",
        "outputId": "9127ac4f-741f-4440-b8de-d940ec891661"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "\n",
            "Train loss: 0.67302 , Train accuracy: 76.40%\n",
            "Test loss: 0.50624 | Test accuracy: 82.48%\n",
            "\n",
            "It took 15.079216354999971 seconds to complete the process\n",
            "\n",
            "Epoch: 1\n",
            "\n",
            "Train loss: 0.47769 , Train accuracy: 83.13%\n",
            "Test loss: 0.55363 | Test accuracy: 79.61%\n",
            "\n",
            "It took 27.261247873999764 seconds to complete the process\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Train loss: 0.44968 , Train accuracy: 84.13%\n",
            "Test loss: 0.50916 | Test accuracy: 82.02%\n",
            "\n",
            "It took 39.49276252799973 seconds to complete the process\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Train loss: 0.43075 , Train accuracy: 84.74%\n",
            "Test loss: 0.45663 | Test accuracy: 83.87%\n",
            "\n",
            "It took 50.97972917600009 seconds to complete the process\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "Train loss: 0.42173 , Train accuracy: 85.00%\n",
            "Test loss: 0.45727 | Test accuracy: 84.07%\n",
            "\n",
            "It took 62.39452786399988 seconds to complete the process\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model evaluation function\n",
        "def model_eval(model: torch.nn.Module,\n",
        "               dataLoader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "  eval_acc = 0\n",
        "  eval_loss = 0\n",
        "  for X, y in dataLoader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    eval_loss += loss_fn(y_pred, y)\n",
        "    eval_acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim=1))\n",
        "\n",
        "  eval_loss /= len(dataLoader)\n",
        "  eval_acc /= len(dataLoader)\n",
        "  return {\"model_name\": model.__class__.__name__,\n",
        "          \"loss\": eval_loss.item(),\n",
        "          \"accuracy\": eval_acc}\n"
      ],
      "metadata": {
        "id": "Dlov6K9ELGzR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model0_results = model_eval(model = model_0,\n",
        "               dataLoader = test_dataloader,\n",
        "               loss_fn = loss_function,\n",
        "               accuracy_fn = accuracy_fn,\n",
        "               device = device)\n",
        "model0_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF9ov_ZFMBtC",
        "outputId": "0b849054-2d2c-4fa7-f39a-ee9e82544aa2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'ModelV0',\n",
              " 'loss': 0.4572727084159851,\n",
              " 'accuracy': 84.06549520766774}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a model with CNNs\n",
        "class ModelV1(nn.Module):\n",
        "  def __init__(self, input_shape:int, hidden_units:int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = input_shape,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  padding = 1,\n",
        "                  stride = 1),\n",
        "\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  padding = 1,\n",
        "                  stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2,\n",
        "                     stride = 2)\n",
        "        )\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  padding = 1,\n",
        "                  stride = 1),\n",
        "\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels = hidden_units,\n",
        "                  out_channels = hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  padding = 1,\n",
        "                  stride = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2,\n",
        "                     stride = 2)\n",
        "        )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units*7*7,\n",
        "                  out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x:torch.Tensor):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "model_1 = ModelV1(1, 10 , len(class_names))\n",
        "model_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAfqOINXPqGn",
        "outputId": "f109ee0c-0655-43a6-fd7f-e10030799c28"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelV1(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                             lr=0.1)"
      ],
      "metadata": {
        "id": "n4ajkObwirE4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and testing the model\n",
        "train_time_start = timer()\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch: {epoch}\\n\")\n",
        "  train_step(dataLoader = train_dataloader,\n",
        "             model = model_1,\n",
        "             optimizer = optimizer,\n",
        "             loss_fn = loss_function,\n",
        "             accuracy_fn = accuracy_fn)\n",
        "  test_step(dataLoader=test_dataloader,\n",
        "            model=model_1,\n",
        "            loss_fn=loss_function,\n",
        "            accuracy_fn=accuracy_fn\n",
        "            )\n",
        "  train_time_end = timer()\n",
        "  print(f\"It took {train_time_end - train_time_start} seconds to complete the process\\n\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp_jdMGvhaOr",
        "outputId": "25e0090f-4c7c-4468-eb99-9c2f65cb56a3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "\n",
            "Train loss: 1.06556 , Train accuracy: 60.08%\n",
            "Test loss: 0.47086 | Test accuracy: 83.06%\n",
            "\n",
            "It took 18.439391015999718 seconds to complete the process\n",
            "\n",
            "Epoch: 1\n",
            "\n",
            "Train loss: 0.39134 , Train accuracy: 85.78%\n",
            "Test loss: 0.39435 | Test accuracy: 85.62%\n",
            "\n",
            "It took 31.57566443299993 seconds to complete the process\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Train loss: 0.34223 , Train accuracy: 87.59%\n",
            "Test loss: 0.34594 | Test accuracy: 88.08%\n",
            "\n",
            "It took 44.57355544899974 seconds to complete the process\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Train loss: 0.31945 , Train accuracy: 88.34%\n",
            "Test loss: 0.35068 | Test accuracy: 86.78%\n",
            "\n",
            "It took 57.63232601899972 seconds to complete the process\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "Train loss: 0.30383 , Train accuracy: 89.00%\n",
            "Test loss: 0.31748 | Test accuracy: 88.76%\n",
            "\n",
            "It took 70.68479333300002 seconds to complete the process\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1_results = model_eval(model = model_1,\n",
        "               dataLoader = test_dataloader,\n",
        "               loss_fn = loss_function,\n",
        "               accuracy_fn = accuracy_fn,\n",
        "               device = device)\n",
        "model1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGst8n7K7evV",
        "outputId": "415b76e9-8bcc-4d7e-b260-262827ef32e9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'ModelV1',\n",
              " 'loss': 0.31747761368751526,\n",
              " 'accuracy': 88.75798722044729}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_comparison = pd.DataFrame([model0_results, model1_results])\n",
        "results_comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Ez3s-WXj73ab",
        "outputId": "7d019df7-56ca-42ff-f36c-78bef9520e1b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  model_name      loss   accuracy\n",
              "0    ModelV0  0.457273  84.065495\n",
              "1    ModelV1  0.317478  88.757987"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8efdc78-26d6-40e3-86f5-aeb51abc6c62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ModelV0</td>\n",
              "      <td>0.457273</td>\n",
              "      <td>84.065495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ModelV1</td>\n",
              "      <td>0.317478</td>\n",
              "      <td>88.757987</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8efdc78-26d6-40e3-86f5-aeb51abc6c62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8efdc78-26d6-40e3-86f5-aeb51abc6c62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8efdc78-26d6-40e3-86f5-aeb51abc6c62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the best model\n",
        "from pathlib import Path\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents = True,\n",
        "                       exist_ok = True)\n",
        "\n",
        "MODEL_NAME = \"FashionMNIST_CNN_model.pth\"\n",
        "SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
        "\n",
        "torch.save(obj = model_1.state_dict(),\n",
        "           f = SAVE_PATH)\n",
        "SAVE_PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xRtVaLfCN8h",
        "outputId": "e91ba0a9-e5e2-4093-b783-634a86019e0d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('models/FashionMNIST_CNN_model.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      sample = torch.unsqueeze(sample, dim = 0).to(device)\n",
        "\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim = 0)\n",
        "\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "AD6mQekYOoAm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k = 9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "test_samples[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggg4YCC7yXdy",
        "outputId": "40f33bb9-51e6-46bd-af88-1eec7f5935db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.2706, 0.5961, 0.3412, 0.2941, 0.3176, 0.3020, 0.3098,\n",
              "          0.5137, 0.5255, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.2353, 0.6235,\n",
              "          0.9176, 0.9922, 0.9216, 0.9765, 0.9059, 0.7294, 0.7922, 0.9804,\n",
              "          0.9765, 0.9216, 0.8902, 0.8000, 0.5098, 0.2275, 0.0000, 0.0000,\n",
              "          0.0039, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0039, 0.0000, 0.1804, 0.7608, 0.8706, 0.8784,\n",
              "          0.8235, 0.8118, 0.8039, 0.7804, 0.7725, 0.7412, 0.7333, 0.7176,\n",
              "          0.7137, 0.7373, 0.7725, 0.8000, 0.8275, 0.8549, 0.6275, 0.0000,\n",
              "          0.0000, 0.0039, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.7922, 0.8745, 0.8078, 0.8118,\n",
              "          0.8000, 0.8235, 0.8275, 0.8196, 0.8118, 0.7922, 0.7843, 0.7804,\n",
              "          0.7843, 0.7647, 0.7882, 0.7686, 0.7686, 0.7647, 0.8510, 0.2510,\n",
              "          0.0000, 0.0235, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.4392, 0.8824, 0.8118, 0.8431, 0.8471,\n",
              "          0.8196, 0.8196, 0.8196, 0.7922, 0.7882, 0.7961, 0.7882, 0.7686,\n",
              "          0.7765, 0.7686, 0.7843, 0.7804, 0.7765, 0.7765, 0.8157, 0.6706,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.6431, 0.8745, 0.8196, 0.8510, 0.8353,\n",
              "          0.8196, 0.8235, 0.8157, 0.8000, 0.7882, 0.7922, 0.7961, 0.7765,\n",
              "          0.7765, 0.7804, 0.7804, 0.7647, 0.7843, 0.7647, 0.7961, 0.8235,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.7529, 0.8549, 0.8314, 0.8471, 0.8353,\n",
              "          0.8157, 0.8157, 0.8118, 0.7961, 0.7843, 0.7843, 0.7961, 0.7843,\n",
              "          0.7804, 0.7725, 0.7569, 0.7569, 0.8000, 0.7922, 0.8039, 0.8627,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.8510, 0.8510, 0.8392, 0.8706, 0.8392,\n",
              "          0.8275, 0.8157, 0.8118, 0.7961, 0.7843, 0.7804, 0.8000, 0.7922,\n",
              "          0.7843, 0.7725, 0.7608, 0.7647, 0.8157, 0.8196, 0.8000, 0.8980,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.9216, 0.8353, 0.8275, 0.9882, 0.9294,\n",
              "          0.8471, 0.8196, 0.8235, 0.8078, 0.7922, 0.8000, 0.7961, 0.7922,\n",
              "          0.7843, 0.7725, 0.7804, 0.7804, 0.9608, 0.8627, 0.7882, 0.7765,\n",
              "          0.0941, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.9333, 0.8196, 0.9451, 0.6235, 0.6510,\n",
              "          0.9412, 0.8157, 0.8196, 0.8118, 0.8000, 0.8000, 0.7961, 0.7922,\n",
              "          0.7843, 0.7843, 0.7725, 0.8706, 0.5098, 0.8824, 0.7961, 0.7922,\n",
              "          0.1608, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0235, 0.9647, 0.8000, 0.9922, 0.3451, 0.3686,\n",
              "          0.9961, 0.7843, 0.8275, 0.8196, 0.8118, 0.8000, 0.7922, 0.7922,\n",
              "          0.7882, 0.7804, 0.7843, 0.8627, 0.0627, 0.9843, 0.8039, 0.8039,\n",
              "          0.2353, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0941, 0.9765, 0.8039, 1.0000, 0.1725, 0.2039,\n",
              "          1.0000, 0.7804, 0.8314, 0.8196, 0.8157, 0.8039, 0.7961, 0.7882,\n",
              "          0.7843, 0.7765, 0.8196, 0.8039, 0.0000, 0.9961, 0.8196, 0.8196,\n",
              "          0.2784, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.1373, 0.8510, 0.8235, 1.0000, 0.0784, 0.0627,\n",
              "          1.0000, 0.7882, 0.8275, 0.8157, 0.8078, 0.8078, 0.8118, 0.7804,\n",
              "          0.7647, 0.7529, 0.8275, 0.7451, 0.0000, 0.9961, 0.8275, 0.8431,\n",
              "          0.3412, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.1608, 0.8588, 0.8235, 1.0000, 0.0588, 0.0000,\n",
              "          1.0000, 0.8196, 0.8314, 0.8275, 0.8078, 0.8039, 0.8039, 0.7804,\n",
              "          0.7647, 0.7569, 0.8353, 0.7373, 0.0000, 0.8941, 0.8549, 0.8314,\n",
              "          0.4471, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.1882, 0.8667, 0.8235, 1.0000, 0.0275, 0.0000,\n",
              "          1.0000, 0.8196, 0.8353, 0.8353, 0.8039, 0.8078, 0.8118, 0.7843,\n",
              "          0.7686, 0.7686, 0.8588, 0.7294, 0.0000, 0.7098, 0.8941, 0.8235,\n",
              "          0.6039, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.2275, 0.8745, 0.8275, 1.0000, 0.0000, 0.0000,\n",
              "          1.0000, 0.8157, 0.8392, 0.8431, 0.8078, 0.8118, 0.8196, 0.7922,\n",
              "          0.7765, 0.7882, 0.8745, 0.6941, 0.0000, 0.5176, 0.9255, 0.8275,\n",
              "          0.7216, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.2902, 0.8824, 0.8392, 0.9961, 0.0000, 0.0000,\n",
              "          0.9961, 0.8235, 0.8431, 0.8471, 0.8039, 0.8196, 0.8196, 0.7961,\n",
              "          0.7843, 0.7569, 0.8902, 0.6706, 0.0000, 0.3529, 0.9373, 0.8235,\n",
              "          0.8157, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.2902, 0.8784, 0.8431, 0.9882, 0.0000, 0.0000,\n",
              "          0.9961, 0.8235, 0.8431, 0.8471, 0.8000, 0.8196, 0.8275, 0.7961,\n",
              "          0.7804, 0.7529, 0.8353, 0.6824, 0.0000, 0.2078, 0.9333, 0.8196,\n",
              "          0.7569, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.3059, 0.8784, 0.8510, 0.9294, 0.0000, 0.0235,\n",
              "          0.9961, 0.8314, 0.8471, 0.8471, 0.7922, 0.8275, 0.8314, 0.7961,\n",
              "          0.7725, 0.7765, 0.8235, 0.7451, 0.0000, 0.0431, 0.9059, 0.8275,\n",
              "          0.7725, 0.0353, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.3137, 0.8784, 0.8588, 0.9059, 0.0000, 0.1059,\n",
              "          1.0000, 0.8353, 0.8549, 0.8510, 0.7922, 0.8275, 0.8392, 0.8000,\n",
              "          0.7765, 0.7882, 0.8078, 0.8784, 0.0000, 0.0000, 0.9922, 0.8549,\n",
              "          0.8000, 0.1176, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.3294, 0.8902, 0.8706, 0.8549, 0.0000, 0.2275,\n",
              "          1.0000, 0.8275, 0.8745, 0.8588, 0.7961, 0.8314, 0.8431, 0.8078,\n",
              "          0.7922, 0.7882, 0.8000, 0.9255, 0.0000, 0.0000, 0.9569, 0.8667,\n",
              "          0.8078, 0.1804, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.3451, 0.8941, 0.8902, 0.7098, 0.0000, 0.2784,\n",
              "          1.0000, 0.8196, 0.8784, 0.8471, 0.8000, 0.8353, 0.8431, 0.8118,\n",
              "          0.7843, 0.8000, 0.8157, 0.8824, 0.0000, 0.0000, 0.8392, 0.8784,\n",
              "          0.8039, 0.2196, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.3647, 0.9020, 0.9176, 0.5255, 0.0000, 0.3373,\n",
              "          0.9176, 0.8235, 0.8863, 0.8353, 0.7961, 0.8353, 0.8510, 0.8196,\n",
              "          0.7804, 0.7961, 0.8157, 0.9059, 0.0000, 0.0000, 0.7255, 0.8980,\n",
              "          0.8000, 0.2275, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.3922, 0.8980, 0.9333, 0.4275, 0.0000, 0.3961,\n",
              "          0.9059, 0.8314, 0.8824, 0.8353, 0.8118, 0.8353, 0.8471, 0.8235,\n",
              "          0.7922, 0.8000, 0.8235, 0.9569, 0.0000, 0.0000, 0.6392, 0.9098,\n",
              "          0.8039, 0.2510, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.4510, 0.9137, 0.9216, 0.3451, 0.0000, 0.3255,\n",
              "          0.9294, 0.8235, 0.8510, 0.8157, 0.8118, 0.8196, 0.8314, 0.8275,\n",
              "          0.7882, 0.7961, 0.8000, 0.8078, 0.0000, 0.0000, 0.4235, 0.9255,\n",
              "          0.8118, 0.2980, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.4510, 0.8863, 0.8980, 0.2627, 0.0000, 0.1059,\n",
              "          0.8941, 0.9294, 0.9294, 0.8980, 0.9059, 0.8980, 0.8863, 0.8902,\n",
              "          0.8627, 0.8667, 0.8902, 0.7529, 0.0000, 0.0000, 0.2902, 0.9020,\n",
              "          0.8196, 0.3569, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.5843, 0.9843, 0.9333, 0.1451, 0.0000, 0.0000,\n",
              "          0.1686, 0.4000, 0.4745, 0.5137, 0.5961, 0.6431, 0.6549, 0.6745,\n",
              "          0.5961, 0.5098, 0.2980, 0.0588, 0.0000, 0.0000, 0.2353, 0.9451,\n",
              "          0.9137, 0.5059, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.1961, 0.6314, 0.4510, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5216,\n",
              "          0.5882, 0.1333, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S0BE2eay1KQ",
        "outputId": "950a783f-12bb-4c13-96f0-74e71c16d318"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = make_predictions(model = model_1,\n",
        "                              data = test_samples)\n",
        "\n",
        "pred_probs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOwGywxZy_Aa",
        "outputId": "e263544e-afb6-40c5-ae3d-d7f478b8c63a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.3122e-04, 1.4576e-05, 9.8416e-01, 1.6107e-04, 5.9493e-04, 3.7247e-06,\n",
              "        1.4320e-02, 1.4703e-08, 8.7360e-06, 2.9442e-06])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes = pred_probs.argmax(dim = 1)\n",
        "pred_classes[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFNaqdhYzK2_",
        "outputId": "999244de-7b80-42f5-e2c5-bcb567f89651"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels, pred_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTtKjcOizcII",
        "outputId": "b4ce392b-fdfb-4d85-edbf-8ee1c2bf1f0b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2, 4, 4, 4, 3, 5, 5, 1, 0], tensor([2, 4, 4, 4, 3, 5, 5, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}