{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpStVoH9HBy/BR3QYcodL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parthivvarma2004/FashionMNIST_Computer_vision/blob/main/FashionMNIST_Computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PXfpNdoZRzOI"
      },
      "outputs": [],
      "source": [
        "#Importing dependencies\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading training and testing data\n",
        "train_data = datasets.FashionMNIST(root = 'data', train = True, download = True, transform = ToTensor())\n",
        "test_data = datasets.FashionMNIST(root = 'data', train = False, download = True, transform = ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjrMcuZRSsd9",
        "outputId": "e9432fac-2a1f-4a06-d67c-0dc024977fce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 17746805.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 307300.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5536088.43it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5935205.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if data has been downloaded in the correct way\n",
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhzTUKdXTXt5",
        "outputId": "e898ba9f-d0ba-416c-844a-ebfcd31ef37e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07t7DBIWafpA",
        "outputId": "bb68df95-2f28-420a-8757-744c9e257ad8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC3e27Faa-kl",
        "outputId": "e7c3ef70-f5e7-468b-e2b5-6b8aab950c1e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "           0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,   1,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
              "          36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,   0,   3],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,\n",
              "         102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,  15],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  69,\n",
              "         207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88, 172,  66],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0, 200,\n",
              "         232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196, 229,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 183,\n",
              "         225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245, 173,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 193,\n",
              "         228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243, 202,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12, 219,\n",
              "         220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244,\n",
              "         222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55, 236,\n",
              "         228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,  92,   0],\n",
              "        [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237, 226,\n",
              "         217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,  77,   0],\n",
              "        [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228, 207,\n",
              "         213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244, 159,   0],\n",
              "        [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217, 226,\n",
              "         200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238, 215,   0],\n",
              "        [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200, 159,\n",
              "         245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232, 246,   0],\n",
              "        [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80,\n",
              "         150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0],\n",
              "        [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
              "          65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,  29],\n",
              "        [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198, 213,\n",
              "         240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221, 230,  67],\n",
              "        [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219, 221,\n",
              "         220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205, 206, 115],\n",
              "        [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211, 210,\n",
              "         200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177, 210,  92],\n",
              "        [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189, 188,\n",
              "         193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216, 170,   0],\n",
              "        [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244, 221,\n",
              "         220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH9U206vbEWo",
        "outputId": "bc47185f-d1ae-4098-a53f-3e670aed1f03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display all the different labels/class names\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehgx0Eb9bTnC",
        "outputId": "b3adb006-a930-4e58-dde1-c3e5c4fd3d36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the image for data visualization\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(class_names[label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "s0S87sdObUQC",
        "outputId": "2d931f79-fb69-452c-b409-db734c1e7276"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ankle boot')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = False)"
      ],
      "metadata": {
        "id": "fV4kQnbIbUNh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VvSU3_TbULJ",
        "outputId": "59c1a793-3db2-4ca5-aef1-19f742d4cd40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1875"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7biogznbbT-S",
        "outputId": "59f4b20d-e0be-4b0d-cc37-a3310916582e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "313"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we flatten our tensors as linear layers in the nn module work with single vectors\n",
        "#First attempt at building a solution - linear and non linear layers (Relu())\n",
        "from torch import nn\n",
        "class ModelV0(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(nn.Flatten(),\n",
        "                                      nn.Linear(in_features=input_shape, out_features = hidden_units),\n",
        "                                      nn.ReLU(),\n",
        "                                      nn.Linear(in_features = hidden_units, out_features = output_shape),\n",
        "                                      nn.ReLU()\n",
        "                                      )\n",
        "    def forward(self, x:torch.Tensor):\n",
        "      return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "Cqy2T70Uglgv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we define the gpu as device to make the process faster\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yugytv2qSWL5",
        "outputId": "5b8e9109-962d-4154-9568-d492105e06ef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Flattening the model will cause the vector to be of size 28*28 = 784, so we use input_shape = 784, hidden_units = 10 (arbitrary small number),\n",
        "#and output_units = len(class_names)\n",
        "\n",
        "model_0  = ModelV0(input_shape = 784, hidden_units = 10, output_shape = len(class_names)).to(device)\n"
      ],
      "metadata": {
        "id": "qhkmqtDxR8yp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ul__5MV7mY",
        "outputId": "f5747f90-0d4a-449f-a7cd-aa3f32be0b2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0153, -0.0270, -0.0253,  ..., -0.0147,  0.0348, -0.0227],\n",
              "        [-0.0225,  0.0249,  0.0311,  ..., -0.0242, -0.0175, -0.0125],\n",
              "        [ 0.0112,  0.0124, -0.0097,  ...,  0.0071,  0.0100, -0.0090],\n",
              "        ...,\n",
              "        [ 0.0254, -0.0143,  0.0336,  ..., -0.0257, -0.0095, -0.0163],\n",
              "        [ 0.0198,  0.0061, -0.0304,  ..., -0.0199, -0.0021,  0.0226],\n",
              "        [-0.0215,  0.0158, -0.0047,  ...,  0.0068, -0.0092,  0.0122]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_0.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD902q9NWQ5E",
        "outputId": "bea77f92-a0bd-4725-b4f2-656cc3be43c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "eH5gToh0Wket"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating an accuracy function to use later\n",
        "def accuracy_fn(y_true: torch.Tensor, y_pred: torch.Tensor):\n",
        "  matches = torch.eq(y_true, y_pred).sum().item()\n",
        "  return ((matches/len(y_pred))*100)"
      ],
      "metadata": {
        "id": "P-Z3v4XQfD8Q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and testing functions\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataLoader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device:torch.device = device):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for batch, (X,y) in  enumerate(dataLoader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = loss_fn(y_pred,y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim=1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss/= len(dataLoader)\n",
        "    train_acc /= len(dataLoader)\n",
        "    print(f\"Train loss: {train_loss:.5f} , Train accuracy: {train_acc:.2f}\")\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataLoader: torch.utils.data.DataLoader,\n",
        "              accuracy_fn,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              optimizer: torch.optim.Optimizer,\n",
        "              device: torch.device = device):\n",
        "  test_loss = 0\n",
        "  test_acc = 0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in dataLoader:\n",
        "      X.to(device)\n",
        "      y.to(device)\n",
        "\n",
        "      test_pred = model(X)\n",
        "\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(y_true = y, y_pred = test_pred.argmax(dim = 1))\n",
        "\n",
        "      test_loss /= len(dataLoader)\n",
        "      test_acc /= len(dataLoader)\n",
        "      print(f\"Test loss: {test_loss:.5f} , Test accuracy: {test_acc:.2f}\")"
      ],
      "metadata": {
        "id": "uphPnZqKdhdb"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}